{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create a dataset of all the companies in the Y Combinator Startup Directory including the following fields:\n",
    "\n",
    "- company_id\n",
    "- company_name\n",
    "- one_liner\n",
    "- year_founded\n",
    "- batch_name (e.g. W20, S19)\n",
    "- tags (e.g. marketplace, fintech, edtech)\n",
    "- ycdc_status (e.g. Public, Inactive)\n",
    "- location\n",
    "  - city\n",
    "  - state\n",
    "  - country\n",
    "- team_size\n",
    "- url\n",
    "- long_description\n",
    "- date_fetched\n",
    "\n",
    "Data visualizations:\n",
    "\n",
    "- map of all startups by location\n",
    "- startups by batch, team_size, and tags\n",
    "- trends by batch using description (NLP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todos\n",
    "\n",
    "- [x] instantiate first driver\n",
    "- [x] enable scrolling until the end of the page\n",
    "- [x] fetch urls from start url\n",
    "- [x] click on 'See all options'\n",
    "- [x] click on batches recursively\n",
    "- [x] fetch all urls from one batch\n",
    "- [x] print script runtime\n",
    "- [x] add tqdm\n",
    "- [ ] scrape fields from each startup url\n",
    "- [ ] make driver headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Firefox()\n",
    "page = \"https://www.ycombinator.com/companies\"\n",
    "driver.get(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click 'See all options'\n",
    "see_all_options = driver.find_element(By.LINK_TEXT, 'See all options')\n",
    "see_all_options.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasons = ['W', 'S', 'IK',]\n",
    "# decades = [0, 1, 2,]\n",
    "\n",
    "def compile_batches():\n",
    "    \"\"\"Returns elements of checkboxes from all batches.\"\"\"\n",
    "    pattern = re.compile(r'^(W|S|IK)[012]')\n",
    "    bx = driver.find_elements(By.XPATH, '//label')\n",
    "    for element in bx:\n",
    "        if pattern.match(element.text):\n",
    "            yield element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python\n",
    "\n",
    "def scroll_to_bottom():\n",
    "    \"\"\"Scrolls to the bottom of the page.\"\"\"\n",
    "    # get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # wait to load page\n",
    "        sleep(3)\n",
    "\n",
    "        # calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_url_paths():\n",
    "    \"\"\"Returns a generator with url paths for all companies.\"\"\"\n",
    "    # contains 'companies' but not 'founders'\n",
    "    elements = driver.find_elements(By.XPATH, ('//a[contains(@href,\"/companies/\") and not(contains(@href,\"founders\"))]'))\n",
    "    for url in elements:\n",
    "        yield url.get_attribute('href') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_urls_to_file(ul: list):\n",
    "    \"\"\"Appends a list of company urls to a file.\"\"\"\n",
    "    with open('start_urls.txt', 'w') as f:\n",
    "        json.dump(ul, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the main script to write all start urls to a file.\"\"\"\n",
    "    print(f\"Attempting to scrape links from {page}.\")\n",
    "    ulist = []\n",
    "    # compile an array of batches (checkbox elements)\n",
    "    batches = compile_batches()\n",
    "\n",
    "    for b in tqdm(list(batches)[-2::]):\n",
    "        # filter companies\n",
    "        b.click()\n",
    "\n",
    "        # scroll down to load all companies\n",
    "        scroll_to_bottom()\n",
    "\n",
    "        # fetch links and append them to ulist\n",
    "        urls = [u for u in fetch_url_paths()]\n",
    "        ulist.extend(urls)\n",
    "\n",
    "        # uncheck the batch checkbox\n",
    "        b.click()\n",
    "    # driver.quit()\n",
    "\n",
    "    write_urls_to_file(ulist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to scrape companies from https://www.ycombinator.com/companies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 0.1 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "q = driver.page_source\n",
    "print(q)\n",
    "\n",
    "with open('output.html', 'w') as f:\n",
    "    f.write(cap.stdout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c047662a869790a3a05a70c8de1bf09db1b33ed04353761a0d9d8972667c3d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
